---
title: "Generics = n_obs?"
author: "MH Tessler"
date: "7/31/2019"
output: pdf_document
---


```{r}
library(tidyverse)
library(jsonlite)
library(viridis)
library(tidyboot)
library(brms)
library(lme4)
library(lmerTest)
library(ggridges)
library(ggstance)
library(rwebppl)
library(knitr)
library(ggthemes)
theme_set(theme_few())
```

```{r load.data}
data.paths <- c("~/projects/genex/results/gen_example/")

df.subject <- data.frame()
df.trials <- data.frame()
df.attention <- data.frame()
for (data.path in data.paths){
  result.files <- list.files(data.path, pattern="json")

  expt.id <- match(data.path, data.paths)
  for (result_file in result.files) {
    result_json = fromJSON(paste(data.path, result_file, sep ="/"))
    worker.id = result_json$WorkerId
    condition = result_json$answers$condition
    
    df.attention = bind_rows(
      df.attention, 
      data.frame(result_json$answers$sound_check) %>%
        mutate(exptid = expt.id,
               workerid = worker.id)
               #tested_on = as.character(tested_on),
               #response = as.character(response))
    )
      
    df.subject = bind_rows(
      df.subject, 
      data.frame(result_json$answers$subject_information) %>% 
        mutate(
          exptid = expt.id,
          workerid = worker.id,
          language = gsub("\"", "", language),
          enjoyment = gsub("\"", "", enjoyment),
          age = gsub("\"", "", age),
          gender = gsub("\"", "", gender),
          problems = gsub("\"", "", problems),
          comments = gsub("\"", "", comments)
        ) 
    )
    
    data.worker <- data.frame(result_json$answers$trials)
    d.condition <- data.frame(result_json$answers$condition)
    names(d.condition) <- "condition"
    
    if (d.condition$condition == "generic") {
      data.worker$correctId = NA
    }
    
    df.trials = bind_rows(
      df.trials, 
      data.worker %>%
        select(type, singular, featureSingular, response, correctId) %>%
        mutate(exptid = expt.id,
               workerid = worker.id,
               condition = d.condition$condition, 
               level = "subordinate")
        
    )
  }
}

```


```{r load.data super, eval = F}
data.paths <- c("~/projects/genex/results/gen_example_levels/")

df.subject <- data.frame()
df.trials <- data.frame()
df.attention <- data.frame()
for (data.path in data.paths){
  result.files <- list.files(data.path, pattern="json")

  expt.id <- match(data.path, data.paths)
  for (result_file in result.files) {
    result_json = fromJSON(paste(data.path, result_file, sep ="/"))
    worker.id = result_json$WorkerId
    condition = result_json$answers$condition
    
    df.attention = bind_rows(
      df.attention, 
      data.frame(result_json$answers$sound_check) %>%
        mutate(exptid = expt.id,
               workerid = worker.id)
               #tested_on = as.character(tested_on),
               #response = as.character(response))
    )
      
    df.subject = bind_rows(
      df.subject, 
      data.frame(result_json$answers$subject_information) %>% 
        mutate(
          exptid = expt.id,
          workerid = worker.id,
          language = gsub("\"", "", language),
          enjoyment = gsub("\"", "", enjoyment),
          age = gsub("\"", "", age),
          gender = gsub("\"", "", gender),
          problems = gsub("\"", "", problems),
          comments = gsub("\"", "", comments)
        ) 
    )
    
    data.worker <- data.frame(result_json$answers$trials)
    d.condition <- data.frame(result_json$answers$condition)
    names(d.condition) <- "condition"
    
    if (d.condition$condition == "generic") {
      data.worker$correctId = NA
    }
    
    df.trials = bind_rows(
      df.trials, 
      data.worker %>%
        select(type, singular, featureSingular, response, correctId, level) %>%
        mutate(exptid = expt.id,
               workerid = worker.id,
               condition = d.condition$condition)
        
    )
  }
}

```

## Correct ID (attention check)

```{r}
df.trials %>%
  filter(type == 'id') %>%
  group_by(workerid, condition, level) %>%
  summarize(n_correct = sum(correctId)) %>%
  ungroup() %>%
  group_by(n_correct) %>%
  count()
```

### Correct ID by item

```{r}
df.trials %>%
  filter(type == 'id') %>%
  group_by(singular) %>%
  summarize(n_correct = sum(correctId) / n())# %>%
  # ungroup() %>%
  # group_by(n_correct) %>%
  # count()
```

Participants per condition

```{r}
df.trials %>% 
  select(workerid, condition, singular, type) %>%
  filter(singular == "Fep", type == "response") %>%
  group_by(condition) %>%
  count()
```


### Workers pass Correct ID



```{r}
df.id.catch <- df.trials %>%
  filter(type == 'id') %>%
  group_by(workerid, condition) %>%
  summarize(n_correct = sum(correctId),
            #pass = n_correct >= 1)
            pass = n_correct == 3)
```

### Filter out failures to pass attention check

```{r}
df.trials.generics <- df.trials %>%
  filter(condition == "generic")

df.trials.filtered <- df.trials %>%
  left_join(., df.id.catch) %>%
  filter(pass) %>%
  bind_rows(., df.trials.generics)

df.trials.filtered %>%
  group_by(condition, level) %>%
  summarize(n_responses = n()) %>%
  ungroup() %>%
  mutate(n_subj = ifelse(condition =="generic", 
                         n_responses / 3, n_responses / 6)) %>%
  select(-n_responses)
  
#, n_trials = n(),
 #           n = ifelse(condition == "generic", n_trials / 3,  n_trials / 6))
```

# Visualization and analysis

```{r}
df.trials.filtered.recoded <- df.trials.filtered %>%
  filter(type == 'response') %>%
  mutate(featureSingular = ifelse(is.na(featureSingular), "squeaks", featureSingular)) %>%
  mutate(condition = factor(condition,
                            levels = c("accidental",
                                       "2accidental",
                                       "3accidental",
                                       "4accidental",
                                       "pedagogical",
                                       "2pedagogical",
                                       "3pedagogical",
                                       "4pedagogical",
                                       "generic",
                                       "pedageneric"),
                            labels = c("1x Accidental",
                                       "2x Accidental",
                                       "3x Accidental",
                                       "4x Accidental",
                                       "1x Pedagogical",
                                       "2x Pedagogical",
                                       "3x Pedagogical",
                                       "4x Pedagogical",
                                       "Generic",
                                       "Generic \n+ 1x Pedagogical")),
         number = 1) %>%
  group_by(workerid) %>%
  mutate(trial_num = cumsum(number)) %>%
  filter(trial_num <= 3)
```

Number of responses per subject

```{r}
df.trials.filtered.recoded %>%
  group_by(workerid) %>%
  summarize(n = n()) %>%
  ungroup() %>%
  group_by(n) %>%
  count()
```


## Histograms

```{r}
df.trials.filtered %>%
  ggplot(., aes(x = response))+
  geom_histogram()+
  facet_wrap(~condition + level, nrow = 1)+
  scale_x_continuous(breaks = c(0, 1))
```


```{r}
df.trials.filtered.recoded %>%
  ggplot(., aes(x = response))+
  geom_histogram()+
  facet_grid(featureSingular~condition)
```
Trail order

```{r}
df.trials.filtered.recoded %>%
  ggplot(., aes(x = response))+
  geom_histogram()+
  facet_grid(trial_num~condition)
```


## 95 CIs

```{r}
df.bs <- df.trials.filtered.recoded %>%
  group_by(condition, level) %>%
  tidyboot_mean(column = response)
```

```{r}
df.bs %>%
  ggplot(., aes(x = condition, y = mean, ymin = ci_lower,
                ymax = ci_upper)) +
  geom_col(color = 'black', fill = 'white')+
  geom_linerange()
```

### Ridge distribution plots

```{r}
ggplot(df.trials.filtered.recoded, 
       aes(x = response, y = condition, fill = ..x..)) +
  geom_density_ridges_gradient(
    jittered_points = T, alpha = 0.8, scale = 0.95,
    position = position_points_jitter(width = 0.01, height = 0),
    point_shape = '|', point_size = 2.5, point_alpha = 0.3,
    rel_min_height = 0.01, gradient_lwd = 1,
    stat = 'binline', bins = 25, draw_baseline = F
  ) +
  geom_linerangeh(data = df.bs,
    inherit.aes = F,
    aes(xmin = ci_lower, xmax = ci_upper, 
        y = as.numeric(condition)+0.4),
    size = 1.25, color = 'black')+
  geom_vline(data = df.bs %>% filter(condition == "Generic"), 
             inherit.aes = F, linetype = 2, alpha = 0.4,
             aes(xintercept = ci_lower))+
  geom_vline(data = df.bs %>% filter(condition == "Generic"), 
             inherit.aes = F, linetype = 2, alpha = 0.4,
             aes(xintercept = ci_upper))+
  geom_point(data = df.bs,
    inherit.aes = F,
    aes(x = mean,
        y = as.numeric(condition)+0.4),
    size = 3, color = 'black', shape = 3)+
  scale_x_continuous(expand = c(0.01, 0), 
                     limits = c(0, 1.02), 
                     breaks = c(0, 0.25, 0.5, 0.75, 1)) +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_fill_viridis(name = "Implied Prevalence", option = "D",
                     breaks = c(0, 1)) +
  guides(fill = F)+
  #labs(title = 'Temperatures in Lincoln NE in 2016') +
  #theme_ridges(font_size = 13, grid = T) + 
  theme(axis.title.y = element_blank(),
        axis.title.x = element_text(hjust = 0.5, vjust = 0))+
  labs(x = "Probability of Future Instance having Property")

# ggsave("~/projects/generic-interpretation/posters/genex-pilots_8conditions_reordered.pdf",
#        width = 5, height = 5)
ggsave("../writing/cogsci20/figs/genex-pilots_10conditions_reordered.pdf",
       width = 5, height = 5)
```



#### Pedagogical and Generic only

```{r}
generic.and.pedagogical <-  c("1x Pedagogical",
                              "2x Pedagogical",
                              "3x Pedagogical",
                              "Generic",
                              "Generic \n+ 1x Pedagogical")



df.trials.filtered.recoded.ped <- df.trials.filtered.recoded %>% 
  filter(condition %in% generic.and.pedagogical) %>%
  ungroup() %>% 
  mutate(condition = factor(condition, levels = generic.and.pedagogical))

df.bs.ped <- df.bs %>% 
  filter(condition %in% generic.and.pedagogical) %>%
  ungroup() %>% 
  mutate(condition = factor(condition, levels = generic.and.pedagogical))

ggplot(df.trials.filtered.recoded.ped, 
       aes(x = response, y = condition, fill = ..x..)) +
  geom_density_ridges_gradient(
    jittered_points = T, alpha = 0.8, scale = 0.95,
    position = position_points_jitter(width = 0.01, height = 0),
    point_shape = '|', point_size = 2.5, point_alpha = 0.3,
    rel_min_height = 0.01, gradient_lwd = 1,
    stat = 'binline', bins = 25, draw_baseline = F
  ) +
  geom_linerangeh(data =df.bs.ped,
    inherit.aes = F,
    aes(xmin = ci_lower, xmax = ci_upper, 
        y = as.numeric(condition)+0.4),
    size = 1.25, color = 'black')+
  geom_point(data = df.bs.ped,
    inherit.aes = F,
    aes(x = mean,
        y = as.numeric(condition)+0.4),
    size = 4, color = 'black', shape = 3)+
  scale_x_continuous(expand = c(0.01, 0), 
                     limits = c(0, 1.02), 
                     breaks = c(0, 0.25, 0.5, 0.75, 1)) +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_fill_viridis(name = "Implied Prevalence", option = "D",
                     breaks = c(0, 1)) +
  guides(fill = F)+
  #labs(title = 'Temperatures in Lincoln NE in 2016') +
  #theme_ridges(font_size = 13, grid = T) + 
  theme(axis.title.y = element_blank(),
        axis.title.x = element_text(hjust = 0.5, vjust = 0))+
  labs(x = "P(Feature | Category)")

ggsave("~/projects/generic-interpretation/posters/genex-pilots_ped.png",
       width = 5, height =4 )
```

#### Accidental and Generic only

```{r}
generic.and.accidental <-  c("1x Accidental",
                              "2x Accidental",
                              "3x Accidental",
                              "Generic",
                              "Generic \n+ 1x Pedagogical")

df.trials.filtered.recoded.acc <- df.trials.filtered.recoded %>% 
  filter(condition %in% generic.and.accidental) %>%
  ungroup() %>% 
  mutate(condition = factor(condition, levels = generic.and.accidental))

df.bs.acc <- df.bs %>% 
  filter(condition %in% generic.and.accidental) %>%
  ungroup() %>% 
  mutate(condition = factor(condition, levels = generic.and.accidental))

ggplot(df.trials.filtered.recoded.acc, 
       aes(x = response, y = condition, fill = ..x..)) +
  geom_density_ridges_gradient(
    jittered_points = T, alpha = 0.8, scale = 0.95,
    position = position_points_jitter(width = 0.01, height = 0),
    point_shape = '|', point_size = 2.5, point_alpha = 0.3,
    rel_min_height = 0.01, gradient_lwd = 1,
    stat = 'binline', bins = 25, draw_baseline = F
  ) +
  geom_linerangeh(data =df.bs.acc,
    inherit.aes = F,
    aes(xmin = ci_lower, xmax = ci_upper, 
        y = as.numeric(condition)+0.4),
    size = 1.25, color = 'black')+
  geom_point(data = df.bs.acc,
    inherit.aes = F,
    aes(x = mean,
        y = as.numeric(condition)+0.4),
    size = 4, color = 'black', shape = 3)+
  scale_x_continuous(expand = c(0.01, 0), 
                     limits = c(0, 1.02), 
                     breaks = c(0, 0.25, 0.5, 0.75, 1)) +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_fill_viridis(name = "Implied Prevalence", option = "D",
                     breaks = c(0, 1)) +
  guides(fill = F)+
  #labs(title = 'Temperatures in Lincoln NE in 2016') +
  #theme_ridges(font_size = 13, grid = T) + 
  theme(axis.title.y = element_blank(),
        axis.title.x = element_text(hjust = 0.5, vjust = 0))+
  labs(x = "P(Feature | Category)")

ggsave("~/projects/generic-interpretation/posters/genex-pilots_acc.png",
       width = 5, height = 4)
```


# Regression

### Forward difference


```{r}

my.forward.diff = matrix(
  c(7/8, -1/8, -1/8, -1/8, -1/8, -1/8, -1/8, -1/8, 
    6/8, 2/8, -(4/3)/8, -(4/3)/8, -(4/3)/8, -(4/3)/8, -(4/3)/8, -(4/3)/8, 
    5/8, 3/8, 3/8, -11/40, -11/40, -11/40, -11/40, -11/40,
    1/2, 1/2, 1/2, 1/2, -1/2, -1/2, -1/2, -1/2,
    11/40, 11/40, 11/40, 11/40, 11/40, -3/8, -3/8, -5/8,
    (4/3)/8, (4/3)/8, (4/3)/8, (4/3)/8, (4/3)/8, (4/3)/8, -2/8, -6/8,
    1/8, 1/8, 1/8, 1/8, 1/8, 1/8, 1/8, -7/8),
      ncol = 7)


contrasts(df.trials.filtered.recoded$condition) <- my.forward.diff


rs.lm <- lmer(response ~ 
       condition + (1 | workerid) + (1 | singular), data = df.trials.filtered.recoded)

summary(rs.lm)
```

### Dummy coding

```{r}
df.trials.filtered.recoded.genDummy <- df.trials.filtered.recoded %>%
  mutate(condition = factor(condition,
                            levels = c("Generic",
                                       "1x Accidental",
                                       "1x Pedagogical",
                                       "2x Accidental",
                                       "2x Pedagogical",
                                       "3x Accidental",
                                       "3x Pedagogical",
                                       "Generic \n+ 1x Pedagogical")))

contrasts(df.trials.filtered.recoded.genDummy$condition) 

rs.lm.dummy <- lmer(response ~ condition + (1 | workerid) + 
                      (1 | singular), data = df.trials.filtered.recoded.genDummy)

summary(rs.lm.dummy)
```


```{r}
rs.brm.dummy <- brm(response ~ condition + (1 | workerid) + 
                      (1 | singular), 
                    data = df.trials.filtered.recoded.genDummy,
                    chains = 2, cores = 2)
summary(rs.brm.dummy)
```

```{r}
rs.brm.dummy <- brm(response ~ condition + (1 | workerid) + 
                      (1 | singular), 
                    data = df.trials.filtered.recoded.genDummy,
                    chains = 2, cores = 2)
summary(rs.brm.dummy)
```

```{r}
rs.brm.dummy.beta <- brm(response ~ condition + (1 | workerid) + 
                      (1 | singular), 
                    data = df.trials.filtered.recoded.genDummy %>%
                      mutate(response = ifelse(response == 1, 0.999, 
                                               ifelse(response == 0, 0.001, response))),
                    chains = 2, cores = 2, family = Beta()
                    )
summary(rs.brm.dummy.beta)
```

```{r}
rs.brm.dummy.betaInfl <- brm(response ~ condition + (1 | workerid) + 
                      (1 | singular), 
                    data = df.trials.filtered.recoded.genDummy,
                    chains = 2, cores = 2, family = zero_one_inflated_beta()
                    )
summary(rs.brm.dummy.betaInfl)
```

# WebPPL

First, we determine what the right linking function is, within the family of a mixture of Betas. 
- Specfically, how many components do we need? (hypothesis: 2)
- We compute the marginal (log) likelihood of the data for each condition separately, assuming different n_components for the Beta
- we then logsumexp those loglikelihoods to compute a Bayes Factor for each hypothesis (n_component) to decide upon a fixed link function

Second, we take that link function and compute the marginal likelihood of the data for pairwise conditions, assuming that those conditions come from the same vs. different distributions (where each distribution could be a multimodal distribution)

## Marginal Likelihood

### What is the right link function?

```{r}
#n_components <- c(1, 2, 3)
n_components <- c(2)
# steps = 25k --> 30s
rs.wp.ais <- data.frame()

df.filtered.toPass <- df.trials.filtered %>%
  filter(type == "response") %>%
  rowwise() %>%
  mutate(avoided_endval = ifelse(response == 1, 0.999, 
                                 ifelse (response == 0, 0.001, response)))

all_conditions <- unique(df.filtered.toPass$condition)

# t0.start <- Sys.time()

for (cndtn in all_conditions){
  print(cndtn)
  
  df.filtered.toPass.condition <- df.filtered.toPass %>%
    filter(condition == cndtn)

  for (n_c in n_components){
    t1 <- Sys.time()
    
    rs.wp.ais.i <- webppl(
      program_file = "webppl/mixture_of_betas.wppl",
      data = list(responses = df.filtered.toPass.condition,
                  n_components = n_c,
                  ais = T,
                  ais_samples = 1,
                  ais_steps = 5000000),
      chains = 3,
      cores = 3
      )
    
    bind_rows(rs.wp.ais, 
              data.frame(marg_ll = rs.wp.ais.i, n_c = n_c, condition = cndtn, row.names = NULL) %>%
                  mutate(iter = row_number())) -> rs.wp.ais 
    t2 <- Sys.time()
    print(paste("n components =", n_c, " time=", t2-t1))
  }
  
}

# t0.end <- Sys.time()
# print(paste("total time=", t0.end-t0.start))
# 
# rs.wp.ais

write_csv(rs.wp.ais, path = "webppl/output/ais_allConds_nComponents_5000k.csv")
```


```{r}
#rs.wp.ais <- read_csv(file = "webppl/output/ais_allConds_nComponents_50k.csv")

rs.wp.ais %>%
  rowwise() %>%
  mutate(ll = exp(marg_ll)) %>%
  ungroup() %>%
  group_by(condition, n_c) %>%
  summarize(mean_ll = mean(ll),
            log_mean_llh = log(mean_ll)) %>% # average likelihood over chains
  ungroup() %>%
  group_by(n_c) %>%
  summarize(marg_llh = sum(log_mean_llh)) # sum likelihoods over conditions
  
rs.wp.ais %>% 
  group_by(n_c, iter) %>%
  summarize(marg_llh = sum(marg_ll)) %>% 
  kable()
```

#### Bayes Factors

```{r}
rs.wp.ais %>%
  rowwise() %>%
  mutate(ll = exp(marg_ll)) %>%
  ungroup() %>%
  group_by(condition, n_c) %>%
  summarize(mean_ll = mean(ll),
            log_mean_llh = log(mean_ll)) %>% # average likelihood over chains
  ungroup() %>%
  group_by(n_c) %>%
  summarize(marg_llh = sum(log_mean_llh)) %>% # sum likelihoods over conditions
  spread(n_c, marg_llh) %>%
  gather(n_c, val, -`2`) %>%
  mutate(log_bf = `2` - val,
         bf = exp(log_bf)) %>%
  select(n_c, bf, log_bf) %>%
  mutate(n_c = paste("N = 2 vs. N = ", n_c, " Component", sep = "")) %>%
  rename("Model Comparison" = n_c,
         "Log BF" = log_bf,
         "BF"= bf) %>%
  write_csv(., path = "../writing/cogsci20/output_from_r/n_component_bf.csv")
```


### How many observations is one generic worth?

Above, we have the marginal likelihoods for fitting 2 component Mixtures of Betas to each condition. Now we examine the marginal likelihoods for fitting a single 2-component Mixture-of-Betas to the generic condition + other condition. This will tell us how well the generic + [other] conditions are modeled by the same generative process.

```{r}

n_c <- 2
# steps = 25k --> 30s
rs.wp.ais_2cond <- data.frame()

df.filtered.toPass <- df.trials.filtered %>%
  filter(type == "response") %>%
  rowwise() %>%
  mutate(avoided_endval = ifelse(response == 1, 0.999, 
                                 ifelse (response == 0, 0.001, response)))

all_conditions <- unique(df.filtered.toPass$condition)
non_generic_conditions <- all_conditions[all_conditions != "generic"]

for (cndtn in non_generic_conditions_temp){
  t1 <- Sys.time()
  print(cndtn)
  
  df.filtered.toPass.condition <- df.filtered.toPass %>%
    filter(condition %in% c(cndtn, "generic"))
  
  # df.ped <- df.filtered.toPass %>% 
  #   filter(condition == "4pedagogical") %>% 
  #   sample_n(45) 
  # 
  # df.filtered.toPass.condition <- bind_rows(
  #   df.ped, df.filtered.toPass %>% 
  #   filter(condition == "generic")
  # )

  rs.wp.ais.i <- webppl(
    program_file = "webppl/mixture_of_betas.wppl",
    data = list(responses = df.filtered.toPass.condition,
                n_components = n_c,
                ais = T,
                ais_samples = 1,
                ais_steps = 5000000),
    chains = 3,
    cores = 3
    )
    
    bind_rows(rs.wp.ais_2cond, 
              data.frame(marg_ll = rs.wp.ais.i, n_c = n_c, condition = cndtn, row.names = NULL) %>%
                  mutate(iter = row_number())) -> rs.wp.ais_2cond 
    t2 <- Sys.time()
    print(paste("n components =", n_c, " time=", t2-t1))

}

write_csv(rs.wp.ais_2cond, path = "webppl/output/ais_2conds_allConds_nComponents_5000k.csv")
```

```{r}
#rs.wp.ais_2cond <- read_csv(file = "webppl/output/ais_2conds_allConds_nComponents_250k.csv")

rs.wp.ais_2cond %>%
  group_by(condition, n_c) %>%
  summarize(mean_marg_ll = mean(marg_ll)) -> rs.ml.same_distribution

rs.wp.ais %>%
  filter(n_c == 2) %>%
  group_by(condition) %>%
  summarize(mean_marg_ll = mean(marg_ll)) -> rs.ml.ind_distribution

cbind(rs.ml.ind_distribution %>%
  filter(condition != "generic"),
  rs.ml.ind_distribution %>%
    filter(condition == "generic") %>%
    rename(gen = mean_marg_ll) %>%
    select(-condition)) %>%
  mutate(total_marg_ll = mean_marg_ll + gen) -> rs.sum_ml.ind_distribution


left_join(
  rs.ml.same_distribution %>%
    rename(same_dist = mean_marg_ll),
  rs.sum_ml.ind_distribution %>%
    rename(diff_dist = total_marg_ll)
) %>%
  rowwise() %>%
  mutate(log_bf = same_dist - diff_dist,
         bf_gen_equal_obs = exp(log_bf)) %>%
  select(condition, bf_gen_equal_obs, log_bf) %>%
  rename(bf = bf_gen_equal_obs, logbf = log_bf) %>%
  mutate(condition = factor(condition, levels = c("accidental", "2accidental", "3accidental", "4accidental",
                                                  "pedagogical", "2pedagogical", "3pedagogical", "4pedagogical",
                                                  "pedageneric"),
                            labels = c("1 Accidental", "2 Accidental", "3 Accidental", "4 Accidental",
                                       "1 Pedagogical", "2 Pedagogical", "3 Pedagogical", "4 Pedagogical",
                                       "Generic + 1 Pedagogical"))) %>%
  arrange(condition) %>%
  kable()# %>%
  #write_csv(., path = "../writing/cogsci20/output_from_r/n_obs_bf_500k_500k.csv")
```

Chain variability

```{r}
#rs.wp.ais_2cond <- read_csv(file = "webppl/output/ais_2conds_allConds_nComponents_250k.csv")

rs.wp.ais_2cond %>%
  group_by(condition, n_c, iter) %>%
  summarize(mean_marg_ll = mean(marg_ll)) -> rs.ml.same_distribution

rs.wp.ais %>%
  filter(n_c == 2) %>%
  group_by(condition, iter) %>%
  summarize(mean_marg_ll = mean(marg_ll)) -> rs.ml.ind_distribution

left_join(rs.ml.ind_distribution %>%
  filter(condition != "generic"),
  rs.ml.ind_distribution %>%
    filter(condition == "generic") %>%
    rename(gen = mean_marg_ll) %>%
    ungroup() %>%
    select(-condition)) %>%
  mutate(total_marg_ll = mean_marg_ll + gen) -> rs.sum_ml.ind_distribution


left_join(
  rs.ml.same_distribution %>%
    rename(same_dist = mean_marg_ll),
  rs.sum_ml.ind_distribution %>%
    rename(diff_dist = total_marg_ll)
) %>%
  rowwise() %>%
  mutate(log_bf = same_dist - diff_dist,
         bf_gen_equal_obs = exp(log_bf)) %>%
  select(condition, bf_gen_equal_obs, log_bf) %>%
  rename(bf = bf_gen_equal_obs, logbf = log_bf) %>%
  mutate(condition = factor(condition, levels = c("accidental", "2accidental", "3accidental", "4accidental",
                                                  "pedagogical", "2pedagogical", "3pedagogical", "4pedagogical",
                                                  "pedageneric"),
                            labels = c("1 Accidental", "2 Accidental", "3 Accidental", "4 Accidental",
                                       "1 Pedagogical", "2 Pedagogical", "3 Pedagogical", "4 Pedagogical",
                                       "Generic + 1 Pedagogical"))) %>%
  arrange(condition) %>%
  kable() #%>%
  #write_csv(., path = "../writing/cogsci20/output_from_r/n_obs_bf_500k_500k.csv")
```

## Posterior Inference


```{r}
jsonlite::toJSON(head(df.filtered.toPass.condition), pretty = T)

n_samples = 10000

rs.wp.condition <- webppl(
  program_file = "webppl/mixture_of_betas.wppl",
  data = list(responses = df.filtered.toPass.condition,
              n_components = 2,
              ais = F,
              ais_samples = 1,
              ais_steps = 1),
  inference_opts = list(
    method = "MCMC",
    samples = n_samples,
    burn = n_samples/2,
    verbose = T),
  chains = 1,
  cores = 1
  )
```

### Parameter posteriors
```{r}
rs.wp.condition %>%
  ggplot(., aes( x =  value ))+
  geom_histogram()+
  facet_wrap(~Parameter, scales = 'free', nrow = 1)
```
```{r}
rs.wp.condition %>%
  ggplot(., aes( x =  value ))+
  geom_histogram()+
  facet_wrap(~Parameter, scales = 'free', nrow = 1)
```

### Posterior predictives

```{r}
rs.wp.condition.predictives <- rs.wp.condition %>%
  spread(Parameter, value) %>% 
  rowwise() %>%
  mutate(component1 = rbernoulli(n = 1, p = phi0),
         sample1 = rbeta(n = 1, shape1 = a0, shape2 = b0),
         sample2 = rbeta(n = 1, shape1 = a1, shape2 = b1),
         predictive = ifelse(component1, sample1, sample2))

rs.wp.condition.predictives %>%
  ggplot(., aes ( x = predictive))+
  geom_histogram()
```

#### Empirical CDFs

```{r}

bind_rows(
  rs.wp.condition.predictives %>%
    mutate(src = 'model') %>%
    select(src, predictive) %>%
    rename(val = predictive),
  df.filtered.toPass.condition %>%
    mutate(src = 'data') %>%
    select(src, avoided_endval) %>%
    rename(val = avoided_endval)
) %>%
  ggplot(., aes( x = val, color = src))+
    stat_ecdf()+
    #scale_color_solarized()+
    scale_x_continuous(limits = c(-0.01,1.01), breaks = c(0, 0.5, 1)) +
    scale_y_continuous(limits = c(-0.01,1.01), breaks = c(0, 0.5, 1)) +
    theme(strip.text.y = element_text(angle = 0))+
    coord_fixed()
```





## MARGINAL LIKELIHOOD TESTING


```{r}
test.data <- data.frame(
  avoided_endval = c(rbeta(n = 100, shape1 = 10, shape2 = 10), rbeta(n = 100, shape1 = 50, shape2 = 1))
)
```


### AIS

```{r}
qplot(data = test.data, x = avoided_endval, geom = 'histogram')

n_components <- c(1, 2, 3)
# steps = 25k --> 30s
rs.wp.ais <- data.frame()
for (n_c in n_components){
  t1 <- Sys.time()
  
  rs.wp.ais.i <- webppl(
    program_file = "webppl/mixture_of_betas.wppl",
    data = list(responses = test.data,
                n_components = n_c,
                ais = T,
                ais_samples = 1,
                ais_steps = 100000),
    chains = 3,
    cores = 3
    )
  
  bind_rows(rs.wp.ais, 
            data.frame(marg_ll = rs.wp.ais.i, n_c = n_c, row.names = NULL) %>%
                mutate(iter = row_number())) -> rs.wp.ais 
  t2 <- Sys.time()
  print(paste("n components =", n_c, " time=", t2-t1))
}
rs.wp.ais

#write_csv(rs.wp.ais, path = "webppl/output/ais_generic_nComponents_500k.csv")
```

```{r}
rs.wp.ais %>% 
  group_by(n_c) %>%
  summarize(m = mean(marg_ll))
```

### Forward Sampling


```{r}
n_components <- c(1, 2, 3)
# steps = 25k --> 30s
rs.wp.fs <- data.frame()
for (n_c in n_components){
  t1 <- Sys.time()
  
  rs.wp.fs.i <- webppl(
    program_file = "webppl/mixture_of_betas_forwardMarginalLikelihood.wppl",
    data = list(responses = test.data,
                n_components = n_c,
                n_samples = 50000),
    #inference_opts = list(method = "forward", samples = 50000),
    chains = 3,
    cores = 3
    )
  
  bind_rows(rs.wp.fs, 
             data.frame(marg_ll = rs.wp.fs.i, n_c = n_c, row.names = NULL) %>%
                mutate(iter = row_number())) -> rs.wp.fs 
  t2 <- Sys.time()
  print(paste("n components =", n_c, " time=", t2-t1))
}
rs.wp.fs

#write_csv(rs.wp.ais, path = "webppl/output/ais_generic_nComponents_500k.csv")
```

```{r}
rs.wp.fs.save <- bind_rows(rs.wp.fs, rs.wp.fs.save)

rs.wp.fs.save
```


#### Compare Bayes Factors when only have half the data

If we want to employ optional stopping, what would our decisions have been if we only collected half of each of the conditions worth of data?

```{r}

n_c <- 2
n_steps <- 250000
# steps = 25k --> 30s
rs.wp.ais.sameDists <- data.frame()
rs.wp.ais.separateDists <- data.frame()

df.filtered.toPass <- df.trials.filtered %>%
  filter(type == "response") %>%
  rowwise() %>%
  mutate(avoided_endval = ifelse(response == 1, 0.999, 
                                 ifelse (response == 0, 0.001, response)))


data.subset.workerids <- df.filtered.toPass %>%
  distinct(condition, workerid) %>%
  group_by(condition) %>%
  sample_n(20)
  
#all_conditions <- unique(df.filtered.toPass$condition)
all_conditions <- c("4pedagogical", "generic")
non_generic_conditions <- all_conditions[all_conditions != "generic"]

for (cndtn in all_conditions){
  t1 <- Sys.time()
  print(cndtn)
  
  workerids.in.condition <- data.subset.workerids %>%
    filter(condition == cndtn) %>%
    pull(workerid)
  
  df.cndtn <- df.filtered.toPass %>%
      filter(condition == cndtn)
  
  if (cndtn != "generic"){
    df.cndtn <- df.cndtn %>% filter(workerid %in% workerids.in.condition)
  }
  
  rs.wp.ais.separateDists.i <- webppl(
    program_file = "webppl/mixture_of_betas.wppl",
    data = list(responses = df.cndtn,
                n_components = n_c,
                ais = T,
                ais_samples = 1,
                ais_steps = n_steps),
    chains = 3,
    cores = 3
    )
  
    bind_rows(rs.wp.ais.separateDists, 
            data.frame(marg_ll = rs.wp.ais.separateDists.i, n_c = n_c, condition = cndtn, row.names = NULL) %>%
                mutate(iter = row_number())) -> rs.wp.ais.separateDists 
      
  
  if (cndtn != "generic"){
    df.filtered.toPass.condition <- bind_rows(
      df.cndtn, df.filtered.toPass %>%
      filter(condition == "generic")
    )

    rs.wp.ais.sameDists.i <- webppl(
      program_file = "webppl/mixture_of_betas.wppl",
      data = list(responses = df.filtered.toPass.condition,
                  n_components = n_c,
                  ais = T,
                  ais_samples = 1,
                  ais_steps = n_steps),
      chains = 3,
      cores = 3
      )
    
    bind_rows(rs.wp.ais.sameDists, 
              data.frame(marg_ll = rs.wp.ais.sameDists.i, n_c = n_c, condition = cndtn, row.names = NULL) %>%
                  mutate(iter = row_number())) -> rs.wp.ais.sameDists
  }
    
    t2 <- Sys.time()
    print(paste("n components =", n_c, " time=", t2-t1))

}

#write_csv(rs.wp.ais_2cond, path = "webppl/output/ais_2conds_allConds_nComponents_250k.csv")

```

```{r}
#rs.wp.ais_2cond <- read_csv(file = "webppl/output/ais_2conds_allConds_nComponents_250k.csv")

rs.wp.ais.sameDists %>%
  group_by(condition, n_c) %>%
  summarize(mean_marg_ll = mean(marg_ll)) -> rs.ml.halfData_same_distribution

rs.wp.ais.separateDists %>%
  filter(n_c == 2) %>%
  group_by(condition) %>%
  summarize(mean_marg_ll = mean(marg_ll)) -> rs.ml.halfData_ind_distribution

cbind(rs.ml.halfData_ind_distribution %>%
  filter(condition != "generic"),
  rs.ml.halfData_ind_distribution %>%
    filter(condition == "generic") %>%
    rename(gen = mean_marg_ll) %>%
    select(-condition)) %>%
  mutate(total_marg_ll = mean_marg_ll + gen) -> rs.sum_ml.ind_distribution


left_join(
  rs.ml.same_distribution %>%
    rename(same_dist = mean_marg_ll),
  rs.sum_ml.ind_distribution %>%
    rename(diff_dist = total_marg_ll)
) %>%
  rowwise() %>%
  mutate(log_bf = same_dist - diff_dist,
         bf_gen_equal_obs = exp(log_bf)) %>%
  select(condition, bf_gen_equal_obs, log_bf) %>%
  rename(bf = bf_gen_equal_obs, logbf = log_bf) %>%
  mutate(condition = factor(condition, levels = c("accidental", "2accidental", "3accidental", "4accidental",
                                                  "pedagogical", "2pedagogical", "3pedagogical", "4pedagogical",
                                                  "pedageneric"),
                            labels = c("1 Accidental", "2 Accidental", "3 Accidental", "4 Accidental",
                                       "1 Pedagogical", "2 Pedagogical", "3 Pedagogical", "4 Pedagogical",
                                       "Generic + 1 Pedagogical"))) %>%
  arrange(condition) %>%
  #kable()  %>%
  write_csv(., path = "../writing/cogsci20/output_from_r/n_obs_bf.csv")
```
